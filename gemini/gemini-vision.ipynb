{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEqbX8OhE8y9"
   },
   "source": [
    "# Getting Started with the Gemini Pro Vision Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tFy3H3aPgx12",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip3 install --upgrade --user google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5Xep4W9lq-Z"
   },
   "source": [
    "### Restart current runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRvKdaPDTznN",
    "outputId": "154a71b5-f302-4f53-ed2f-b3e5fef9195b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('./.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = os.environ.get('PROJECT_ID')\n",
    "LOCATION=os.environ.get('LOCATION')\n",
    "print(PROJECT_ID)\n",
    "print(LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nqwi-5ufWp_B",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lRyTw2iPhEXG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GenerativeModel(\"gemini-1.0-pro-vision-001\")\n",
    "#model = GenerativeModel(\"gemini-1.5-pro-preview-0409\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PIL_Image\n",
    "import json\n",
    "\n",
    "def logo_vadidation(image_path) -> None:\n",
    "  old1 = Image.load_from_file(\"./images/old_1080/old_logo_1.jpg\")\n",
    "  old2 = Image.load_from_file(\"./images/old_1080/old_logo_2.jpg\")\n",
    "  new1 = Image.load_from_file(\"./images/new_1080/new_logo_1.jpg\")\n",
    "  new2 = Image.load_from_file(\"./images/new_1080/new_logo_2.jpg\")\n",
    "\n",
    "  logo_img = Image.load_from_file(image_path)\n",
    "\n",
    "  # Prepare prompts\n",
    "  prompt1 = \"\"\"I am a QA engineer to verify company\\'s logo CI. Classify an input logo image as 'old' or 'new' \n",
    "  according to the examples for 'old' and 'new' logos and its style guide. Provide the output JSON.\n",
    "  \n",
    "  examples :\n",
    "    - 'old' logo style : Round red color Logo shape looks like a 3D image, so it has a shadow inside the red round shape.\n",
    "    - 'old' logo examples :\n",
    "  \"\"\"\n",
    "  prompt2 = \"\"\"\n",
    "    - 'new' logo style: Round red color Logo shape looks like a 2D image, so it looks flat.\n",
    "    - 'new' logo exaples : \n",
    "  \"\"\"\n",
    "  prompt3 =\"\"\"\n",
    "  input image :\n",
    "  \"\"\"\n",
    "  prompt4 =\"\"\"\n",
    "  output: \n",
    "  {\n",
    "  \\\"style\\\" : \\\"new\\\"\n",
    "  }\n",
    "  \"\"\"\n",
    "\n",
    "  # Prepare contents\n",
    "  contents = [prompt1, old1, old2, prompt2, new1, new2, prompt3, logo_img, prompt4]\n",
    "\n",
    "  generation_config = {\n",
    "    \"max_output_tokens\": 2048,\n",
    "    \"temperature\": 0.0,\n",
    "    \"top_p\": 0.9,\n",
    "    \"top_k\": 1,\n",
    "  }\n",
    "\n",
    "  responses = model.generate_content(contents, generation_config=generation_config,stream=True)\n",
    "\n",
    "  #print(responses)\n",
    "  #print_multimodal_prompt(contents)\n",
    "  for response in responses:\n",
    "      #ret = response.text\n",
    "      print(response.text)\n",
    "      #print(json.loads(response.text)[\"style\"])\n",
    "\n",
    "  display(logo_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(45, 68):  # range(start, stop) is exclusive of the stop value\n",
    "    logo_vadidation(f\"./images/new_1080/new_logo_{i}.jpg\")\n",
    "    #logo_vadidation(f\"./images/old/old_logo_{i}.jpg\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
